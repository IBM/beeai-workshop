# Set your API key here for OpenAI API. You can use "placeholder" for local ollama
OPENAI_API_KEY=placeholder

# If using ollama to run models locally:
PROVIDER_ID=ollama
MODEL_ID=granite4:tiny-h
OLLAMA_BASE_URL=http://localhost:11434/v1

# BeeAI logging
# Use WARNING for less logging, DEBUG for more.
BEEAI_LOG_LEVEL=INFO

