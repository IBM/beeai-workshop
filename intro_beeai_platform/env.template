# Set your API key here for OpenAI API or use "placeholder" for local ollama
OPENAI_API_KEY=placeholder

# To use OpenAI as a provider (tested with gtp-5-mini)
# uncomment this section and
# ** remember to comment out Ollama section **
# PROVIDER_ID=openai
# MODEL_ID=gpt-5-mini

# If using ollama to run models locally:
# ** remember to comment out OpenAI section **
OLLAMA_BASE_URL=http://localhost:11434/v1
PROVIDER_ID=ollama
MODEL_ID=granite4:tiny-h

# BeeAI logging
# Use WARNING for less logging, DEBUG for more.
BEEAI_LOG_LEVEL=INFO

