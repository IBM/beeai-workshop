{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RDMNr1S86fWn"
   },
   "source": [
    "# Welcome to the BeeAI Framework Workshop üêù\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bv4UxF3f3_-c"
   },
   "source": [
    "üéØ Scenario: The Field Marketing Lead has asked you to help prepare their team for conference season. You create a Conference Prep Agent that uses 3 tools: web search to collect relevant news and search for up to date information, Wikipedia to provide company history and details, and the team's internal notes and artifacts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CguLI81u3_gg"
   },
   "source": [
    "üìö What You'll Learn\n",
    "\n",
    "- System Prompts - The foundation of agent behavior\n",
    "- RequirementAgent - BeeAI's powerful agent implementation that provides control over agent behavior\n",
    "- LLM Providers - Local and hosted model options\n",
    "- Memory Systems - Maintaining conversation context\n",
    "- Tools Integration - Extending agent capabilities\n",
    "- Conditional Requirements - Enforcing business logic and rules\n",
    "- Observability - Monitoring and debugging agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jk5sBse_66_H"
   },
   "source": [
    "## üîß Setup\n",
    "First, let's install the BeeAI Framework and set up our environment.\n",
    "\n",
    "- setting up the observability so we can capture and log the actions our agent takes\n",
    "- getting the \"internal documents\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ivhQKPrL652y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2mUsing Python 3.12.6 environment at: /Users/markstur/gh/beeai-workshop/beeai_docling_mellea/beeai-framework/.venv\u001B[0m\n",
      "\u001B[2K\u001B[2mResolved \u001B[1m207 packages\u001B[0m \u001B[2min 519ms\u001B[0m\u001B[0m                                       \u001B[0m\n",
      "\u001B[2K\u001B[2mPrepared \u001B[1m1 package\u001B[0m \u001B[2min 0.33ms\u001B[0m\u001B[0m                                             \n",
      "\u001B[2mUninstalled \u001B[1m1 package\u001B[0m \u001B[2min 1ms\u001B[0m\u001B[0m\n",
      "\u001B[2K\u001B[2mInstalled \u001B[1m1 package\u001B[0m \u001B[2min 2ms\u001B[0m\u001B[0m                                  \u001B[0m\n",
      " \u001B[31m-\u001B[39m \u001B[1msqlean-py\u001B[0m\u001B[2m==3.49.1\u001B[0m\n",
      " \u001B[32m+\u001B[39m \u001B[1msqlean-py\u001B[0m\u001B[2m==3.50.4.5\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install -Uqq \"arize-phoenix==11.37.0\" \\\n",
    "    \"s3fs\" \\\n",
    "    \"fsspec==2025.3.0\" \\\n",
    "    \"gcsfs\" \\\n",
    "    \"nest_asyncio\" \\\n",
    "    \"jedi\" \\\n",
    "    \"markdown==3.9\" \\\n",
    "    \"opentelemetry-api==1.37.0\" \\\n",
    "    \"opentelemetry-api==1.37.0\" \\\n",
    "    \"openinference-instrumentation-beeai==0.1.13\" \\\n",
    "    \"beeai-framework[duckduckgo,llama_index,wikipedia]==0.1.59\" \\\n",
    "    \"langchain\" \\\n",
    "    \"langchain-community==0.3.27\" \\\n",
    "    \"python-dotenv~=1.1.1\" \\\n",
    "    \"wikipedia\" \\\n",
    "    \"unstructured==0.18.15\" \\\n",
    "    \"requests==2.32.4\"\n",
    "\n",
    "# The following wraps Notebook output\n",
    "from IPython.display import HTML, display\n",
    "def set_css(*_, **__):\n",
    "    display(HTML(\"\\n<style>\\n pre{\\n white-space: pre-wrap;\\n}\\n</style>\\n\"))\n",
    "get_ipython().events.register(\"pre_run_cell\", set_css)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dF_sHdJY7LnK"
   },
   "source": [
    "Now let's import the necessary modules:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DN1XO5lj7MoB"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       " pre{\n",
       " white-space: pre-wrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import time\n",
    "import phoenix as px\n",
    "import ipywidgets\n",
    "from typing import Any\n",
    "from datetime import date\n",
    "from pydantic import BaseModel, Field\n",
    "from dotenv import load_dotenv\n",
    "from beeai_framework.agents.requirement import RequirementAgent\n",
    "from beeai_framework.agents.requirement.types import RequirementAgentOutput\n",
    "from beeai_framework.agents.requirement.requirements import Requirement, Rule\n",
    "from beeai_framework.agents.requirement.requirements.conditional import ConditionalRequirement\n",
    "from beeai_framework.backend import ChatModel, ChatModelParameters\n",
    "from beeai_framework.backend.document_loader import DocumentLoader\n",
    "from beeai_framework.backend.embedding import EmbeddingModel\n",
    "from beeai_framework.backend.text_splitter import TextSplitter\n",
    "from beeai_framework.backend.vector_store import VectorStore\n",
    "from beeai_framework.context import RunContext\n",
    "from beeai_framework.emitter.emitter import Emitter, EventMeta\n",
    "from beeai_framework.emitter.types import EmitterOptions\n",
    "from beeai_framework.memory import UnconstrainedMemory\n",
    "from beeai_framework.middleware.trajectory import GlobalTrajectoryMiddleware\n",
    "from beeai_framework.tools import StringToolOutput, Tool, tool\n",
    "from beeai_framework.tools.search.duckduckgo import DuckDuckGoSearchTool\n",
    "from beeai_framework.tools.search.retrieval import VectorStoreSearchTool\n",
    "from beeai_framework.tools.think import ThinkTool\n",
    "from beeai_framework.tools.weather import OpenMeteoTool\n",
    "from beeai_framework.tools.types import ToolRunOptions\n",
    "from openinference.instrumentation.beeai import BeeAIInstrumentor\n",
    "from opentelemetry import trace as trace_api\n",
    "from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n",
    "from opentelemetry.sdk import trace as trace_sdk\n",
    "from opentelemetry.sdk.resources import Resource\n",
    "from opentelemetry.sdk.trace.export import SimpleSpanProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lweJWWT0BJI1"
   },
   "source": [
    " ## 1Ô∏è‚É£ LLM Providers: Choose Your AI Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y9YkgZafBnFO"
   },
   "source": [
    "BeeAI Framework supports 10+ LLM providers including Ollama, Groq, OpenAI, Watsonx.ai, and more, giving you flexibility to choose local or hosted models based on your needs. In this workshop we'll be working Ollama, so you will be running the model locally. You can find the documentation on how to connect to other providers [here](https://framework.beeai.dev/modules/backend).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ug4p_c8ktOp"
   },
   "source": [
    "### *‚ùó* Exercise: Select your Language Model Provider\n",
    "\n",
    "Change the `provider` and `model` variables to your desired provider and model.\n",
    "\n",
    "If you select a provider that requires an API key URL or Project_ID, select the key icon on the left menu and set the variables to match those in the userdata.get() function.\n",
    "\n",
    "Try several models to see how your agent performs. Note that you may need to modify the system prompt for each model, as they all have their own system prompt best practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BBNZGq4Gvhyc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       " pre{\n",
       " white-space: pre-wrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63261da261c34a789433d6ce47745866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(options=('ollama', 'openai', 'watsonx'), value='ollama')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Use widgets to show provider choices\n",
    "providers=ipywidgets.ToggleButtons(options=['ollama','openai','watsonx'])\n",
    "display(providers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9mmEwaxPxrJA"
   },
   "source": [
    "In Colab, install and start Ollama for providing the Embedding Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "YdDRJpoPhvrz"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       " pre{\n",
       " white-space: pre-wrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "provider=providers.value\n",
    "# Ollama - No parameters required\n",
    "if provider==\"ollama\":\n",
    "    model=\"granite4:tiny-h\"\n",
    "    #model=\"granite3.3\"\n",
    "    provider_model=provider+\":\"+model\n",
    "    llm=ChatModel.from_name(provider_model, ChatModelParameters(temperature=0))\n",
    "# OpenAI - Place OpenAI API Key in Colab Secrets (key icon) as OPENAI_KEY\n",
    "elif provider==\"openai\":\n",
    "    model=\"gpt-5-mini\"\n",
    "    provider_model=provider+\":\"+model\n",
    "    api_key = userdata.get('OPENAI_KEY')             #Set secret value using key in left menu\n",
    "    llm=ChatModel.from_name(provider_model, ChatModelParameters(temperature=1), api_key=api_key)\n",
    "# WatsonX - Place Project ID, API Key and WatsonX URL in Colab Secrets (key icon)\n",
    "elif provider==\"watsonx\":\n",
    "    model=\"ibm/granite-3-8b-instruct\"\n",
    "    provider_model=provider+\":\"+model\n",
    "    project_id = userdata.get('WATSONX_PROJECT_ID')  #Set secret value using key in left menu\n",
    "    api_key = userdata.get('WATSONX_APIKEY')         #Set secret value using key in left menu\n",
    "    base_url = userdata.get('WATSONX_URL')           #Set secret value using key in left menu\n",
    "    llm=ChatModel.from_name(provider_model, ChatModelParameters(temperature=0), project_id=project_id, api_key=api_key, base_url=base_url)\n",
    "else:\n",
    "  print(\"Provider \" + provider + \" undefined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NarMFy4272JG"
   },
   "source": [
    "## 2Ô∏è‚É£ Understanding System Prompts: The Agent's Foundation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZwVazkU7-14"
   },
   "source": [
    "What is a System Prompt?\n",
    "A system prompt is the foundational instruction that defines your agent's identity, role, and behavior. Think of it as the agent's \"job description\" and \"training manual\" rolled into one. Each model responds differently to the same system prompt, so experimentation is necessary.\n",
    "\n",
    "Some key components of a strong system prompt:\n",
    "\n",
    "- Identity: Who is the agent?\n",
    "- Role: What is their function?\n",
    "- Context: What environment are they operating in?\n",
    "- Rules: What constraints and guidelines must they follow?\n",
    "- Knowledge: What domain-specific information do they need?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oFXat-h6Nh1V"
   },
   "source": [
    "### *‚ùó* Exercise: Customize Your System Prompt\n",
    "Try modifying the system prompt. Customize the \"basic rules\" section to add your own. Note that changes to the system prompt will affect the performance of the model. Creating a great `System Prompt` is an art, not a science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_FOCLkIn73sk"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       " pre{\n",
       " white-space: pre-wrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "todays_date = date.today().strftime(\"%B %d, %Y\")\n",
    "instruct_prompt = f\"\"\"You help field marketing teams prep for conferences by answering questions on companies that they need to prepare to talk to. You produce quick and actionable briefs, doing your best to anwer the user's question.\n",
    "\n",
    "Today's date is {todays_date}.\n",
    "\n",
    "Tools:\n",
    "- ThinkTool: Helps you plan and reason before you act. Use this tool when you need to think.\n",
    "- DuckDuckGoSearchTool: Use this tool to collect current information on agendas, speakers, news, competitor moves. Include title + date + link to the resources you find in your answer. Do not use this tool for internal notes or artifacts.\n",
    "- wikipedia_tool: Use this tool to get company/org history (not for breaking news). Only look up company names as the input.\n",
    "- internal_document_search: past meetings, playbooks, artifacts. If you use information from this in yoour response, label it as as [Internal]. Always use this tool when internal notes or content is references.\n",
    "\n",
    "Basic Rules:\n",
    "- Be concise and practical.\n",
    "- Favor recent info (agenda/news ‚â§30 days; exec changes/funding ‚â§180 days); flag older items.\n",
    "- If you don't know, say so. Don't make things up.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Ad__zpmDqjR"
   },
   "source": [
    "## 3Ô∏è‚É£ Memory Systems: Maintaining Context across iterations or sessions\n",
    "Why Memory Matters\n",
    "Short term memory allows agents to:\n",
    "- Remember previous conversation turns\n",
    "- Build on past interactions\n",
    "- Maintain context across multiple queries\n",
    "\n",
    "Long Term memory allows agents to:\n",
    "- Learn from user preferences\n",
    "- Provided a grounded source of truth\n",
    "- Pull data from non public data sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qi5dXiK6OOtv"
   },
   "source": [
    "### *‚ùó* Exercise: Choose your memory strategy\n",
    "`Memory` is an important piece of AI agents. Experiment with the different startegies by running only 1 of the cells and finishing the notebook. Optionally, once you have ran the entire notebook, come back and select a differnt memory approach and see how that affects the agent output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BeeAI Memory Types**\n",
    "\n",
    "BeeAI Framework provides four memory strategies optimized for different use cases, with support for custom memory:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sSpQsDGkHqHa"
   },
   "source": [
    "1. SlidingWindowMemory\n",
    "- Use case: Production applications with long conversations\n",
    "- Behavior: Maintains a fixed number of recent messages\n",
    "- Pros: Controlled memory usage, predictable costs\n",
    "- Cons: May lose important early context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "oZjJBeplHpxT"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       " pre{\n",
       " white-space: pre-wrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from beeai_framework.memory import SlidingMemory, SlidingMemoryConfig\n",
    "\n",
    "memory = SlidingMemory(SlidingMemoryConfig(\n",
    "            size=3,\n",
    "            handlers={\"removal_selector\": lambda messages: messages[0]} # Remove the oldest message\n",
    "            ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JiT_l0YnH0BB"
   },
   "source": [
    "2. TokenWindowMemory\n",
    "Use case: Cost-sensitive applications\n",
    "Behavior: Maintains messages within token budget\n",
    "Pros: Cost control, adapts to message length\n",
    "Cons: Complex to predict exact retention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "FBfTRJgHH8pG"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       " pre{\n",
       " white-space: pre-wrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from beeai_framework.memory import TokenMemory\n",
    "import math\n",
    "\n",
    "memory = TokenMemory(\n",
    "    llm=llm,\n",
    "    max_tokens=None,  # Will be inferred from LLM\n",
    "    capacity_threshold=0.75,\n",
    "    sync_threshold=0.25,\n",
    "    handlers={\n",
    "        \"removal_selector\": lambda messages: next((msg for msg in messages if msg.role != Role.SYSTEM), messages[0]),\n",
    "        \"estimate\": lambda msg: math.ceil((len(msg.role) + len(msg.text)) / 4),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "egdGlIjfIAEp"
   },
   "source": [
    "3. SummarizeMemory\n",
    "- Use case: Long-running agents that need historical context\n",
    "- Behavior: Summarizes old messages to maintain key information\n",
    "- Pros: Retains important information efficiently\n",
    "- Cons: May lose nuanced details in summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "MBM6nxYaIBDA"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       " pre{\n",
       " white-space: pre-wrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from beeai_framework.memory import SummarizeMemory\n",
    "\n",
    "memory = SummarizeMemory(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RhD7dnMuD-Uz"
   },
   "source": [
    "4. UnconstrainedMemory (Default)\n",
    "\n",
    "- Useful for: Development, testing, simple applications\n",
    "- Behavior: Stores all messages indefinitely\n",
    "- Pros: Simple, maintains full context\n",
    "- Cons: Can become expensive with long conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "U4q3OUmRC5xI"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       " pre{\n",
       " white-space: pre-wrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from beeai_framework.memory import UnconstrainedMemory\n",
    "\n",
    "memory = UnconstrainedMemory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "022_BaOVIPtv"
   },
   "source": [
    "### *‚ùó* Exercise: Memory Comparison\n",
    "Chose the memory type you want your agent to have. You can also go back and compare your choice of memory types and how it affected the agent response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t3KvR8_nr28N"
   },
   "source": [
    "## 4Ô∏è‚É£ Tools: Enabling LLMs to Take Action\n",
    "\n",
    "What Are Tools?\n",
    "Tools are external capabilities that extend your agent beyond just generating text. They can be API calls, code, or even calls to other AI models. They can allow agents to:\n",
    "\n",
    "- Access real-time data (internet search, API calls to live data)\n",
    "- Perform calculations (using code generation tools)\n",
    "- Interact with APIs (databases, web services)\n",
    "- Process files (call functions that read, modify, or write files)\n",
    "- Interact with `MCP Servers`\n",
    "\n",
    "The BeeAI framework provides [built in tools](https://framework.beeai.dev/modules/tools#built-in-tools) for common tool types, but also provides the ability to create [custom tools](https://framework.beeai.dev/modules/tools#creating-custom-tools)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ou-4PH6dtlSD"
   },
   "source": [
    "### Adding Framework Provided Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T1r2mzGnxf1Q"
   },
   "source": [
    "The **Think tool** encourages a Re-Act pattern where the agent reasons and plans before calling a tool.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "9hA0-Yo8r17M"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       " pre{\n",
       " white-space: pre-wrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from beeai_framework.tools.think import ThinkTool\n",
    "\n",
    "think_tool = ThinkTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N57fUNvKyFKR"
   },
   "source": [
    "The **DuckDuckGoSearchTool** is a Web Search tool that provides relevant data from the internet to the LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "JjHWPVb5yO4D"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       " pre{\n",
       " white-space: pre-wrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from beeai_framework.tools.search.duckduckgo import DuckDuckGoSearchTool\n",
    "\n",
    "search_tool = DuckDuckGoSearchTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hagkWZpGOGb"
   },
   "source": [
    "### Adding Custom Tools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nz0IdEMzGWN6"
   },
   "source": [
    "There are 2 ways to provide custom tools to your agent. For simple tools you can use the `@tool` decorator above the function. For more complex tools, you can extend the `Tool Class` and customize things such as the run time and tool execution.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wGFtLc9EQ8Kk"
   },
   "source": [
    "We will create a simple custom tool with the `@tool` decorator. Our tool must have a doc string, so that the agent understands when and how it should use that tool. The tool name will defualt to the function name.\n",
    "\n",
    "To learn more about advanced tool customization, take a look at this section in the [documentation](https://framework.beeai.dev/modules/tools#advanced-custom-tool)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "hH9q2IxxGC7H"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       " pre{\n",
       " white-space: pre-wrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from beeai_framework.tools.search.wikipedia import WikipediaTool, WikipediaToolInput\n",
    "\n",
    "@tool\n",
    "async def wikipedia_tool(query: str) -> str:\n",
    "  \"\"\"\n",
    "  Search factual and historical information, including biography, history, politics, geography, society, culture,\n",
    "  science, technology, people, animal species, mathematics, and other subjects.\n",
    "\n",
    "  Args:\n",
    "      query: The topic or question to search for on Wikipedia.\n",
    "\n",
    "  Returns:\n",
    "      The information found via searching Wikipedia.\n",
    "  \"\"\"\n",
    "  full_text = False\n",
    "  language = \"en\"\n",
    "  tool = WikipediaTool(language=language)\n",
    "  response = await tool.run(WikipediaToolInput(query=query, full_text=False))\n",
    "  return response.get_text_content()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7zwInfQoGhNc"
   },
   "source": [
    "## 5Ô∏è‚É£ Creating a RAG (Retrieval Augmented Generation) Tool to Search Internal Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YjGTjXzSRTv9"
   },
   "source": [
    "`RAG` (Retrieval-Augmented Generation) is ‚Äúsearch + write‚Äù: you ask a question, the system retrieves the most relevant snippets from an indexed knowledge base (via embeddings) and the model composes an answer grounded in those snippets.\n",
    "\n",
    "**We created synthetic (made-up) documents to simulate a company knowledge base:**\n",
    "- Security checklists\n",
    "- Call notes\n",
    "- Artifacts\n",
    "\n",
    "We made sets of these for Spotify, Siemens, and Moderna.\n",
    "\n",
    "**Important:** This is demonstration-only data and does not reflect real information about those companies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JwgXCM1QU-nP"
   },
   "source": [
    "The BeeAI Framework has built in abstractions to make RAG simple to implement. Read more about it [here](https://framework.beeai.dev/modules/rag)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8YZs3LUoVOgL"
   },
   "source": [
    "First, we must pull an embedding model which converts text into numerical vectors so we can compare meanings and retrieve the most relevant snippets. The original document is:\n",
    "1. preprocessed (cleaned + broken into chunks)\n",
    "2. ran through the embedding algorithm\n",
    "3. stored in the vector database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "GwbUILLBtRKO"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       " pre{\n",
       " white-space: pre-wrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ‚†ã \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ‚†ô \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ‚†π \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ‚†∏ \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ‚†º \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest \u001B[K\n",
      "pulling 970aa74c0a90: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè 274 MB                         \u001B[K\n",
      "pulling c71d239df917: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  11 KB                         \u001B[K\n",
      "pulling ce4a164fc046: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   17 B                         \u001B[K\n",
      "pulling 31df23ea7daa: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  420 B                         \u001B[K\n",
      "verifying sha256 digest \u001B[K\n",
      "writing manifest \u001B[K\n",
      "success \u001B[K\u001B[?25h\u001B[?2026l\n"
     ]
    }
   ],
   "source": [
    "!ollama pull nomic-embed-text:latest\n",
    "embedding_model = EmbeddingModel.from_name(\"ollama:nomic-embed-text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LiC9dmdPWEkK"
   },
   "source": [
    "### *‚ùó* Exercise: Internal documents\n",
    "Take a look at the internal documents so you know what type of questions to ask your agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "B6WDtFZRgk_P"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       " pre{\n",
       " white-space: pre-wrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 11271  100 11271    0     0  51523      0 --:--:-- --:--:-- --:--:-- 51465\n",
      "==== RAG DOCUMENT ====\n",
      "Account ID: A001\n",
      "Type: call_note\n",
      "Title: Shopify: Observability & Personalization discussion (Jun 18, 2025)\n",
      "Created At: 2025-06-18T15:40:00Z\n",
      "Author: Jordan Blake\n",
      "Conference ID: None\n",
      "Tags: observability, alert-fatigue, security, ml, personalization, roi\n",
      "\n",
      "Content:\n",
      "Context:\n",
      "Shopify's platform teams are revisiting observability to reduce alert fatigue while the\n",
      "Growth org explores AI-driven merchandising. Attendees included VP Eng Platforms (Marina L.),\n",
      "Security Architect (Sofia N.).\n",
      "\n",
      "Current stack & pain points:\n",
      "- Mixed cloud (GCP + AWS), Kubernetes,\n",
      "Kafka, Prometheus, Grafana, homegrown alert rules. \n",
      "- Noisy alerts with low precision; teams mute\n",
      "channels during oncall rotations. \n",
      "- Limited root-cause hints; SREs manually correlate metrics,\n",
      "logs, and traces. \n",
      "- Security requires tighter access reviews and clearer data residency posture for\n",
      "any ML features.\n",
      "\n",
      "Proposed approach:\n",
      "- Introduce ML anomaly scoring layer that consumes metrics and\n",
      "key business KPIs (checkout success rate, add-to-cart, latency) with seasonality awareness and\n",
      "automatic thresholding. \n",
      "- Provide guided triage: top contributing signals, recent deploy\n",
      "correlation, blast-radius heuristics. \n",
      "- For merchandising, use the same telemetry backbone to\n",
      "connect customer behavior to recommendation outcomes for closed-loop learning.\n",
      "\n",
      "Data handling &\n",
      "residency:\n",
      "- Prefer region-bound processing (NA/EU), with per-tenant encryption and scoped service\n",
      "accounts. \n",
      "- Option to deploy scoring service in Shopify VPC; export only aggregate features when\n",
      "needed for cross-region benchmarking.\n",
      "\n",
      "Success metrics:\n",
      "- Reduce false-positive alerts by 50‚Äì70%\n",
      "within 60 days; median MTTD ‚Üì by 30%; mean MTTR ‚Üì by 20%. \n",
      "- For personalization pilots: +0.4‚Äì0.8 pp\n",
      "CTR uplift on long-tail SKUs; +3‚Äì6% AOV in targeted categories.\n",
      "\n",
      "Risks & constraints:\n",
      "- High traffic\n",
      "spikes around seasonal events; models must adapt quickly. \n",
      "- Access control must integrate with\n",
      "Shopify‚Äôs SSO and approval workflows.\n",
      "\n",
      "Open questions:\n",
      "- Which product areas are safe to start with\n",
      "(e.g., Men‚Äôs Accessories)? \n",
      "- How will security review residency constraints for cross-region\n",
      "benchmarking?\n",
      "\n",
      "Next steps:\n",
      "- Send SOC 2 summary and data-flow diagram; propose a 2-week discovery\n",
      "for alert reduction; schedule ROI-focused demo.\n",
      "\n",
      "\n",
      "==== RAG DOCUMENT ====\n",
      "Account ID: A001\n",
      "Type: artifact\n",
      "Title: ROI model sketch for merchandising uplift (Aug 28, 2025)\n",
      "Created At: 2025-08-28T11:05:00Z\n",
      "Author: Jordan Blake\n",
      "Conference ID: C2025-01\n",
      "Tags: roi, personalization, commerce, ab-test, uplift-modeling\n",
      "\n",
      "Content:\n",
      "Objective:\n",
      "Estimate impact of ML-driven recommendations on click-through rate (CTR), conversion rate\n",
      "(CVR), and average order value (AOV) for a phased rollout beginning with Men‚Äôs Accessories.\n",
      "Baseline & data inputs:\n",
      "- Baseline CTR: 2.1% on recommendation modules; CVR: 3.2% sitewide; AOV:\n",
      "$78; traffic: 18M weekly impressions. \n",
      "- Data features: item embeddings (co-views, co-buys), user\n",
      "affinities, seasonality, margin constraints, inventory health.\n",
      "\n",
      "Intervention assumptions:\n",
      "- Expected\n",
      "CTR lift: +0.4‚Äì0.8 pp; CVR lift: +0.1‚Äì0.3 pp; AOV lift: +3‚Äì6% due to long-tail discovery and better\n",
      "bundling. \n",
      "- Uplift concentrated in cold-start and long-tail SKUs; guardrails cap low-margin\n",
      "exposure.\n",
      "\n",
      "Experiment design:\n",
      "- 50/50 geo or traffic split; sample size powered for 95% confidence\n",
      "within 2 weeks. \n",
      "- Success metric hierarchy: revenue per session > AOV > CTR; include margin-\n",
      "adjusted revenue.\n",
      "\n",
      "Rollout plan:\n",
      "- Phase 0 (2 weeks): offline replay + shadow scoring to validate\n",
      "ranker stability. \n",
      "- Phase 1 (2‚Äì4 weeks): limited online A/B with real-time feedback; track novelty\n",
      "vs. relevance. \n",
      "- Phase 2: progressive exposure to additional categories.\n",
      "\n",
      "Risks & mitigations:\n",
      "-\n",
      "Cold-start for new items ‚Üí hybrid ranker with business rules; \n",
      "- Inventory volatility ‚Üí\n",
      "availability-aware scoring; \n",
      "- Seasonal spikes ‚Üí dynamic exploration rate caps.\n",
      "\n",
      "Example back-of-\n",
      "the-envelope:\n",
      "If CTR increases by 0.6 pp on 18M impressions, that‚Äôs +108k clicks. With a 0.2 pp CVR\n",
      "lift and AOV up 4%, estimated weekly incremental revenue ranges $280k‚Äì$520k (sensitivity attached).\n",
      "Dependencies:\n",
      "- Event stream (Kafka), catalog service, inventory API, consent management, security\n",
      "sign-off on data flows.\n",
      "\n",
      "\n",
      "==== RAG DOCUMENT ====\n",
      "Account ID: A002\n",
      "Type: meeting_note\n",
      "Title: Siemens Energy: Turbine analytics pilot scope (Jul 19, 2025)\n",
      "Created At: 2025-07-19T10:00:00Z\n",
      "Author: Priya Nair\n",
      "Conference ID: None\n",
      "Tags: predictive-maintenance, edge, azure, opc-ua, iot, cmms\n",
      "\n",
      "Content:\n",
      "Attendees & objective:\n",
      "Head of Digital Grid (Lukas M.), Asset Performance Lead (Anika R.). Define a\n",
      "limited-scope predictive maintenance pilot for gas turbines.\n",
      "\n",
      "Sensors & sampling plan:\n",
      "- Vibration\n",
      "(x/y/z accelerometers), temperature (bearing, exhaust), pressure (inlet/outlet), rotational speed.\n",
      "- Target sampling: vibration 1‚Äì5 kHz (edge FFT), others 1‚Äì10 Hz; edge windowing with offline\n",
      "buffering (24‚Äì48h).\n",
      "\n",
      "Edge & ingestion architecture:\n",
      "- Ruggedized Linux gateway with OPC-UA\n",
      "collector; local feature extraction (FFT peaks, kurtosis, crest factor). \n",
      "- Secure MQTT/AMQP uplink\n",
      "to Azure IoT Hub; processing via Azure Functions + Data Explorer; long-term storage in ADLS Gen2;\n",
      "dashboards in Power BI.\n",
      "\n",
      "Modeling & alerting:\n",
      "- Unsupervised anomaly detection (isolation\n",
      "forest/autoencoder) with per-asset baselines; \n",
      "- Health score trendline and predicted time-to-\n",
      "maintenance windows; \n",
      "- Alerts integrated with existing CMMS ticketing and planner workflows.\n",
      "Security & compliance:\n",
      "- Device identity, cert rotation, RBAC via Entra ID; audit trails on all\n",
      "config changes; \n",
      "- Network segmentation, zero-trust connectivity, and customer-managed keys.\n",
      "\n",
      "KPIs &\n",
      "success criteria:\n",
      "- 10‚Äì15% reduction in unexpected outages; 5‚Äì8% spare-part optimization; improved\n",
      "planner efficiency measured by time-to-ticket close. \n",
      "- Pilot duration 12‚Äì16 weeks; success gates at\n",
      "weeks 4, 8, and 12.\n",
      "\n",
      "Open items:\n",
      "- Confirm OPC-UA namespace compatibility across turbine\n",
      "generations; \n",
      "- Validate gateways in high-temperature enclosures; \n",
      "- Determine data localization\n",
      "rules for EU sites.\n",
      "\n",
      "\n",
      "==== RAG DOCUMENT ====\n",
      "Account ID: A002\n",
      "Type: security_checklist\n",
      "Title: Siemens Energy: Security Q&A alignment (Sep 5, 2025)\n",
      "Created At: 2025-09-05T14:20:00Z\n",
      "Author: Priya Nair\n",
      "Conference ID: C2025-01\n",
      "Tags: security, audit, rbac, sso, iso27001, soc2\n",
      "\n",
      "Content:\n",
      "Requested controls:\n",
      "- Single sign-on (SAML/OIDC), enforced MFA; fine-grained RBAC with SoD;\n",
      "immutable audit logs; IP allowlists; private network egress. \n",
      "- Evidence for SOC 2 Type II; mapping\n",
      "to ISO/IEC 27001:2022 Annex A; vulnerability management SLAs; incident response runbooks.\n",
      "\n",
      "Data\n",
      "flows & residency:\n",
      "- Edge features computed locally; telemetry encrypted in transit (TLS 1.2+) and\n",
      "at rest (CMK). \n",
      "- EU data stored in-region with logical separation; cross-region analytics limited\n",
      "to anonymized aggregates.\n",
      "\n",
      "Audit & logging:\n",
      "- Append-only logs with retention ‚â• 400 days; export to\n",
      "customer SIEM; \n",
      "- Tamper-evidence via hash chaining; admin actions require step-up approval.\n",
      "Identity & access:\n",
      "- Role templates: Admin, SecOps, Maintenance Planner, Data Scientist (read-only\n",
      "prod). \n",
      "- JIT elevation for sensitive operations; quarterly access reviews with downloadable\n",
      "attestations.\n",
      "\n",
      "Compliance mapping (high level):\n",
      "- A.5 Information security policies ‚Üí policy docs +\n",
      "training cadence; \n",
      "- A.8 Asset management ‚Üí inventory of gateways and certificates; \n",
      "- A.9 Access\n",
      "control ‚Üí SSO + RBAC; \n",
      "- A.12 Operations security ‚Üí vulnerability and patch KPIs; \n",
      "- A.16 Incident\n",
      "management ‚Üí IR playbooks tied to CMMS tickets.\n",
      "\n",
      "Open questions:\n",
      "- Customer-managed HSM vs. provider\n",
      "KMS; \n",
      "- Pen test window before production pilot; \n",
      "- Frequency of SoD attestations for contractor\n",
      "accounts.\n",
      "\n",
      "\n",
      "==== RAG DOCUMENT ====\n",
      "Account ID: A003\n",
      "Type: call_note\n",
      "Title: Moderna: GxP analytics controls & validation (May 9, 2025)\n",
      "Created At: 2025-05-09T17:30:00Z\n",
      "Author: Alex Chen\n",
      "Conference ID: None\n",
      "Tags: gxp, validation, audit, vpc, cfr-part-11, lineage\n",
      "\n",
      "Content:\n",
      "Context & goals:\n",
      "Clinical Ops and Data Science seek a validated analytics pathway for clinical\n",
      "datasets without slowing research velocity. Attendees: Sr Director Data Science (Mei T.), GxP\n",
      "Compliance Manager (Hannah O.).\n",
      "\n",
      "Validation lifecycle (21 CFR Part 11 aligned):\n",
      "- Requirements ‚Üí\n",
      "design specs ‚Üí risk assessment ‚Üí IQ/OQ/PQ ‚Üí change control with traceability matrix. \n",
      "- Version-lock\n",
      "all components (containers, libraries, models) with checksum verification; freeze training data\n",
      "snapshots.\n",
      "\n",
      "Controls & process:\n",
      "- Immutable audit logs for every pipeline run (who/what/when/why)\n",
      "and dataset lineage (source system, transformations, approvals). \n",
      "- Electronic signatures with dual-\n",
      "approval for releasing validated outputs; reviewer roles separated from authors. \n",
      "- Environment\n",
      "strategy: Sandbox VPC for exploration ‚Üí Staging (pre-validated) ‚Üí Production (validated), with gated\n",
      "promotions.\n",
      "\n",
      "Data classification & privacy:\n",
      "- PHI/PII handling via tokenization; row-level access;\n",
      "encrypted workspaces; activity monitoring with anomaly alerts.\n",
      "\n",
      "KPIs & acceptance:\n",
      "- Reduce time-to-\n",
      "approval for analysis outputs by 30‚Äì40%; zero critical deviations; complete audit trail export < 2\n",
      "minutes.\n",
      "\n",
      "Open items:\n",
      "- Clarify retention periods across studies; align e-signature ceremony with\n",
      "internal SOPs; \n",
      "- Confirm Snowflake + Databricks connectivity pattern under validated constraints.\n",
      "Next steps:\n",
      "- Provide 21 CFR Part 11 alignment doc, sample traceability matrix, and a pilot plan for\n",
      "one Phase II study in the Sandbox VPC.\n",
      "\n",
      "\n",
      "==== RAG DOCUMENT ====\n",
      "Account ID: A003\n",
      "Type: artifact\n",
      "Title: Mini-case: Faster site startup via CTMS integration (Aug 15, 2025)\n",
      "Created At: 2025-08-15T09:45:00Z\n",
      "Author: Alex Chen\n",
      "Conference ID: C2025-01\n",
      "Tags: clinical-ops, ctms, case-study, site-startup, governance, lineage\n",
      "\n",
      "Content:\n",
      "Objective:\n",
      "Demonstrate how tapping CTMS data can shorten site startup timelines by improving\n",
      "feasibility, investigator selection, and activation sequencing.\n",
      "\n",
      "Integration scope:\n",
      "- Systems: CTMS\n",
      "(investigator profiles, site readiness, visit schedules), eTMF (essential docs), feasibility\n",
      "surveys, and contracting milestones. \n",
      "- Ingestion cadence: nightly for master data; hourly for\n",
      "activation status; CDC for high-value tables.\n",
      "\n",
      "Data model & features:\n",
      "- Investigator availability,\n",
      "historical enrollment velocity, protocol fit, competing study load, and regulatory turnaround SLAs.\n",
      "- Predictive signals for sites at risk of delays (missing contracts, IRB lag, staff turnover).\n",
      "Expected impact:\n",
      "- Reduce site startup by 10‚Äì15 days across two Phase II trials by front-loading\n",
      "contracting and targeting high-velocity sites. \n",
      "- Improve screen-to-randomization ratio via better\n",
      "site selection and pre-activation checklists.\n",
      "\n",
      "Workflow & governance:\n",
      "- Role-based dashboards for\n",
      "Clinical Ops; exception queues for at-risk sites; \n",
      "- Validated extracts for downstream analysis with\n",
      "full lineage and e-sign approvals.\n",
      "\n",
      "Risks & mitigations:\n",
      "- Data quality variability across CRO\n",
      "partners ‚Üí automated checks and steward review; \n",
      "- Contracting bottlenecks ‚Üí early flagging and\n",
      "templated playbooks.\n",
      "\n",
      "KPIs:\n",
      "- Median days from site selection to SIV; % of sites activated on first\n",
      "target date; data quality score; number of escalations avoided.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read the synthetic data from the public github repo\n",
    "# !curl --output rag_conference_prep_agent.txt https://raw.githubusercontent.com/IBM/beeai-workshop/refs/heads/main/intro_beeai_framework/rag_conference_prep_agent.txt\n",
    "\n",
    "with open('rag_conference_prep_agent.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJgmnsYUWobK"
   },
   "source": [
    "Load the document using the `DocumentLoader` and split the document into chunks using the `text_splitter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GfzhF8B1cl0I"
   },
   "outputs": [],
   "source": [
    "loader = DocumentLoader.from_name(\n",
    "    name=\"langchain:UnstructuredMarkdownLoader\", file_path=\"rag_conference_prep_agent.txt\"\n",
    ")\n",
    "try:\n",
    "    documents = await loader.load()\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load documents: {e}\")\n",
    "\n",
    "# Split documents into chunks\n",
    "text_splitter = TextSplitter.from_name(\n",
    "    name=\"langchain:RecursiveCharacterTextSplitter\", chunk_size=1000, chunk_overlap=200\n",
    ")\n",
    "try:\n",
    "    documents = await text_splitter.split_documents(documents)\n",
    "except Exception as e:\n",
    "    print(f\"Failed to split documents: {e}\")\n",
    "print(f\"Loaded {len(documents)} document chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XvR8tI6kW8I3"
   },
   "source": [
    "Create the `TemporalVectorStore`, which means this vector store also tracks time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PAO6ChtZW4Co"
   },
   "outputs": [],
   "source": [
    "# Create vector store and add documents\n",
    "vector_store = VectorStore.from_name(name=\"beeai:TemporalVectorStore\", embedding_model=embedding_model)\n",
    "await vector_store.add_documents(documents=documents)\n",
    "print(\"Vector store populated with documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_U9I29QkYLeY"
   },
   "source": [
    "Create the `internal_document_search` tool! Because the `VectorStoreSearchTool` is a built in tool wrapper, we don't need to use the `@tool` decorator or extend the custom `Tool class`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ODEKeUo2YK_a"
   },
   "outputs": [],
   "source": [
    "# Create the vector store search tool\n",
    "internal_document_search = VectorStoreSearchTool(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VkI0FLQfyrqv"
   },
   "source": [
    "## 6Ô∏è‚É£ Conditional Requirements: Guiding Agent Behavior\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rUVF44hCzDIE"
   },
   "source": [
    "What Are Conditional Requirements?\n",
    "[Conditional requirements](https://framework.beeai.dev/experimental/requirement-agent#conditional-requirement) ensure your agents are reliable by controlling when and how tools are used. They're like business rules for agent behavior. You can make them as strict (esentially writing a static workflow) or flexible (no rules! LLM decides) as you'd like.\n",
    "\n",
    "The rules that you enforce may seem simple in the BeeAI framework, but in other frameworks they require ~5X the amount of code. Check out this [blog](https://beeai.dev/blog/reliable-ai-agents) where we built the same agent in BeeAI and other agent framework LangGraph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v67JBs7C1oUs"
   },
   "source": [
    "These conditional requirements enforce the following in only 3 lines of code:\n",
    "1. The agent must call the think tool as the first tool call. It is not allowed to call it consecutive times in a row.\n",
    "2. The wikipedia_tool can only be called after the think tool, but not consecutively. It has a relative priority of 10.\n",
    "3. The DuckDuckGo Internet search tool can also only be called after the Think tool, it is allowed to be called up to 3 times, it must be invoked at least once, and it has a relative priority of 15.\n",
    "4. The internal_document_search tool can only be called after the think tool, it is allowed to be called multiple times in a row, it must be called at least once, and it has a relative priority of 20.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CctVkchzySRt"
   },
   "outputs": [],
   "source": [
    "requirement_1 = ConditionalRequirement(ThinkTool, consecutive_allowed=False, force_at_step=1 )\n",
    "\n",
    "requirement_2 = ConditionalRequirement(wikipedia_tool, only_after=ThinkTool, consecutive_allowed=True, priority=10,)\n",
    "\n",
    "requirement_3 = ConditionalRequirement(DuckDuckGoSearchTool, only_after=ThinkTool, consecutive_allowed=True, min_invocations=1, max_invocations=3 ,priority=15,)\n",
    "\n",
    "requirement_4 = ConditionalRequirement(internal_document_search, only_after=ThinkTool, consecutive_allowed=True, min_invocations=1, priority=20,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFNs-1wIKf9q"
   },
   "source": [
    "## Explore Observability: See what is happening under the hood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ty1ivHWdgs5A"
   },
   "source": [
    "Create the function that sets up observability using `OpenTelemetry` and [Arize's Phoenix Platform](https://arize.com/docs/phoenix/inferences/how-to-inferences/manage-the-app). There a several ways to view what is happening under the hood of your agent. View the observability documentation [here](https://framework.beeai.dev/modules/observability)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Quqo7VbDgph9"
   },
   "outputs": [],
   "source": [
    "def setup_observability(endpoint: str = \"http://localhost:6006/v1/traces\") -> None:\n",
    "    \"\"\"\n",
    "    Sets up OpenTelemetry with OTLP HTTP exporter and instruments the beeai framework.\n",
    "    \"\"\"\n",
    "    resource = Resource(attributes={})\n",
    "    tracer_provider = trace_sdk.TracerProvider(resource=resource)\n",
    "    tracer_provider.add_span_processor(SimpleSpanProcessor(OTLPSpanExporter(endpoint)))\n",
    "    trace_api.set_tracer_provider(tracer_provider)\n",
    "\n",
    "    BeeAIInstrumentor().instrument()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yRlbzqFAKpwy"
   },
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "# Enable OpenTelemetry integration\n",
    "setup_observability(\"http://localhost:6006/v1/traces\")\n",
    "px_session = px.launch_app()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xbktgviaGY-A"
   },
   "source": [
    "##  7Ô∏è‚É£ Assemble Your Reliable BeeAI Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q01Efmh0fuCv"
   },
   "source": [
    "This is the part we've been working towards! Let's assemble the agent with all the parts we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_8e74HSg_omm"
   },
   "outputs": [],
   "source": [
    "agent = RequirementAgent(\n",
    "    llm=llm,\n",
    "    instructions= instruct_prompt,\n",
    "    memory = memory,\n",
    "    tools=[ThinkTool(), DuckDuckGoSearchTool(), wikipedia_tool, internal_document_search],\n",
    "    requirements=[\n",
    "      requirement_1,\n",
    "      requirement_2,\n",
    "      requirement_3,\n",
    "      requirement_4\n",
    "    ],\n",
    "    # Log intermediate steps to the console\n",
    "    middlewares=[GlobalTrajectoryMiddleware(included=[Tool])],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r2sSU9D3f_rd"
   },
   "source": [
    "### *‚ùó* Exercise: Test Your Agent\n",
    "Remember that your agent is meant to prep the field marketing team for upcoming conferences and has a limited set of \"internal documents\". Make up your own question or ask one of the sample ones below!\n",
    "\n",
    "\n",
    "**Sample Questions:**\n",
    "- Brief me for a Shopify meeting at the conference. Give me an overview of the company, some recent news about them, and anything important I need to know from our internal notes.\n",
    "\n",
    "- I'm planning on meeting the Moderna rep at the next conference. Give me a one pager and remind me where we left off on previous discussions.\n",
    "\n",
    "- Build a security talking sheet for Siemens Energy. How does their strategy compare to their competitors'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NrH2avK1i75e"
   },
   "outputs": [],
   "source": [
    "question = \"I'm planning on meeting the Moderna rep at the next conference. Give me a one pager and remind me where we left off on previous internal discussions.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AfZGL8NZjMs5"
   },
   "source": [
    "Run the agent with specific execution settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tOsjZFrhkymC"
   },
   "source": [
    "### *‚ùó* Exercise: Test Your Agent\n",
    "Change the execution settings and see what happens. Does your agent run out of iterations? Every task is different and its important to balance flexibility with control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M05oeIY-_rRe"
   },
   "outputs": [],
   "source": [
    "response = await agent.run(question, max_retries_per_step=3, total_max_retries=25)\n",
    "print(response.last_message.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KMTy7_Q__tSN"
   },
   "outputs": [],
   "source": [
    "px_session.view()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
